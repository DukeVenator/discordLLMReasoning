# LLMCord Python to TypeScript Conversion Plan

This document outlines the plan for converting the existing Python `llmcord` codebase into a new Node.js TypeScript project located in the `LLMcordTS` directory.

**Core Requirements:**

*   Translate Python functionality to TypeScript.
*   Establish a well-structured Node.js project.
*   Support core LLM providers (OpenAI, Gemini, Ollama initially).
*   Maintain SQLite for memory storage.
*   Implement foundational unit tests.
*   **Critical:** Ensure the application handles multiple concurrent conversations asynchronously without blocking.

## Phases

**Phase 1: Project Setup & Core Structure**

1.  **Create Project Directory:** Create the top-level `LLMcordTS` directory.
2.  **Initialize Node.js Project:** Run `npm init -y` inside `LLMcordTS`.
3.  **Install Dependencies:**
    *   Core: `typescript`, `@types/node`, `discord.js`, `js-yaml`, `@types/js-yaml`
    *   HTTP Client: `axios` (or use Node's built-in fetch)
    *   Database: `better-sqlite3`, `@types/better-sqlite3` (or `sqlite3`)
    *   Dev Dependencies: `eslint`, `prettier`, `@typescript-eslint/parser`, `@typescript-eslint/eslint-plugin`, `ts-node`, `nodemon`, `vitest` (or `jest`, `ts-jest`, `@types/jest`), `@vitest/coverage-v8`
4.  **Configure TypeScript:** Create `tsconfig.json` (target ES2022+, module NodeNext, strict, source maps, outDir, rootDir).
5.  **Configure Linting/Formatting:** Set up `.eslintrc.json` and `.prettierrc.json`.
6.  **Define Project Structure:** Create `LLMcordTS/src` with subdirectories: `core`, `discord`, `providers`, `memory`, `reasoning`, `utils`, `types`, `commands`, `status`.
7.  **Add `.gitignore`:** Create a standard Node.js `.gitignore`.

**Phase 2: Configuration & Entry Point**

1.  **Translate `config.py` -> `src/core/config.ts`:** Load `config.yaml`, merge defaults, provide `get()` method, define config interface (`src/types/config.ts`).
2.  **Translate `main.py` -> `src/index.ts`:** Setup logging, initialize and run the main Bot class, handle shutdown.

**Phase 3: Core Bot Logic & Discord Integration (Async Focus)**

1.  **Translate `LLMCordBot` -> `src/core/LLMCordBot.ts`:** Define class, implement `initialize` (load config, init `discord.js` client, HTTP client, stubs for components), implement `run` (login). **Ensure async patterns.**
2.  **Translate Event Handlers -> `src/discord/eventHandlers.ts`:** Implement `onReady`, `onMessageCreate` (rate limit, permissions, filtering, command delegation). **Use async/await.**
3.  **Translate `SlashCommandHandler` -> `src/discord/slashCommandHandler.ts`:** Define/register/handle commands using `discord.js` interactions. **Async handling.**
4.  **Translate `StatusManager` -> `src/status/statusManager.ts`:** Implement status cycling/temporary statuses.

**Phase 4: LLM Providers & Interaction (Async Focus)**

1.  **Define Provider Interface (`src/providers/baseProvider.ts`)**: `generateStream` method signature.
2.  **Implement `ProviderFactory` (`src/providers/providerFactory.ts`)**.
3.  **Implement OpenAI Provider (`src/providers/openaiProvider.ts`)**: Use `openai` library, implement `generateStream`. **Async streaming.**
4.  **Implement Gemini Provider (`src/providers/geminiProvider.ts`)**: Use `@google/genai`, implement `generateStream`. **Async streaming.**
5.  **Implement Ollama Provider (`src/providers/ollamaProvider.ts`)**: Use `axios`/`fetch`, implement `generateStream`. **Async streaming.**
6.  **Integrate Providers:** Use Factory in `LLMCordBot`, call `generateStream` in `processMessage`.
7.  **Translate Response Streaming:** Adapt logic to handle Node.js streams and update Discord messages asynchronously.

**Phase 5: Memory & Reasoning (Concurrency Focus)**

1.  **Translate `MemoryStorage` -> `src/memory/storage.ts`:** Setup SQLite (`better-sqlite3`), translate schema/methods (`get`, `append`, `edit`, `delete`, `condense`). **Ensure concurrent-safe DB access.**
2.  **Translate Memory Command Handling:** Integrate with `MemoryStorage`.
3.  **Translate Memory Parsing:** Parse `[MEM_APPEND]`/`[MEM_REPLACE]` tags asynchronously after LLM response.
4.  **Translate `ReasoningManager` -> `src/reasoning/manager.ts`:** Implement signal check, rate limit, secondary model call. **Async handling.**

    *   Note: Address potential issue from Python version where memory tags (`[MEM_APPEND]`/`[MEM_REPLACE]`) generated by the *reasoning* model might not be processed. Ensure TS version handles this correctly.

**Phase 6: Utilities & Testing (Concurrency Awareness)**

1.  **Translate Utilities:** `RateLimiter`, Permissions, Message History Builder, `MsgNode` type.
2.  **Set up Testing Framework:** Vitest/Jest.
3.  **Write Foundational Unit Tests:** Config, Bot init, Permissions, Rate Limiter, basic Event Handling, Memory Storage (mock DB), Provider Factory/basic interaction (mock API). **Consider async test patterns.**
4.  **Add Run Scripts:** `build`, `start`, `dev`, `lint`, `test` in `package.json`.

**Phase 7: Documentation & Refinement**

1.  **Update `README.md`:** Adapt for TypeScript version.
2.  **Add Code Comments:** JSDoc for clarity.
3.  **Refactor & Polish:** Review for improvements and best practices.

## High-Level Component Interaction

```mermaid
graph TD
    subgraph Discord
        DJS[discord.js Client]
        Handlers[Event Handlers (onReady, onMessageCreate)]
        SlashCmds[Slash Command Handler]
    end

    subgraph Core
        Bot[LLMCordBot]
        Config[Config Module]
        Index[index.ts (Entry Point)]
    end

    subgraph Services
        Providers[Provider Factory] --> ProviderOpenAI[OpenAI Provider]
        Providers --> ProviderGemini[Gemini Provider]
        Providers --> ProviderOllama[Ollama Provider]
        Memory[Memory Storage (SQLite)]
        Reasoning[Reasoning Manager]
        Status[Status Manager]
        RateLimit[Rate Limiter]
    end

    subgraph Utils
        Perms[Permissions Logic]
        History[Message History Builder]
        HTTP[HTTP Client (axios/fetch)]
    end

    Index --> Bot
    Bot --> Config
    Bot --> DJS
    Bot --> Providers
    Bot --> Memory
    Bot --> Reasoning
    Bot --> Status
    Bot --> RateLimit
    Bot --> Perms
    Bot --> History
    Bot --> HTTP

    DJS --> Handlers
    DJS --> SlashCmds
    Handlers --> Bot
    SlashCmds --> Bot

    Bot --> Providers

    subgraph External
        DiscordAPI[Discord API]
        LLM_APIs[LLM APIs (OpenAI, Gemini, Ollama)]
        SQLiteDB[(SQLite DB)]
    end

    DJS <--> DiscordAPI
    ProviderOpenAI <--> LLM_APIs
    ProviderGemini <--> LLM_APIs
    ProviderOllama <--> LLM_APIs
    Memory <--> SQLiteDB